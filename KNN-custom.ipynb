{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fff188d-eff4-4224-b2cc-85e91c2e9779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Processing fold 1...\n",
      "Predicting using k-NN for fold 1...\n",
      "Fold 1: Accuracy = 89.90%, Time = 418.52 seconds\n",
      "Processing fold 2...\n",
      "Predicting using k-NN for fold 2...\n",
      "Fold 2: Accuracy = 93.10%, Time = 699.12 seconds\n",
      "Processing fold 3...\n",
      "Predicting using k-NN for fold 3...\n",
      "Fold 3: Accuracy = 91.30%, Time = 972.67 seconds\n",
      "Processing fold 4...\n",
      "Predicting using k-NN for fold 4...\n",
      "Fold 4: Accuracy = 90.70%, Time = 1253.42 seconds\n",
      "Processing fold 5...\n",
      "Predicting using k-NN for fold 5...\n",
      "Fold 5: Accuracy = 90.60%, Time = 1526.49 seconds\n",
      "Processing fold 6...\n",
      "Predicting using k-NN for fold 6...\n",
      "Fold 6: Accuracy = 91.40%, Time = 1805.21 seconds\n",
      "Processing fold 7...\n",
      "Predicting using k-NN for fold 7...\n",
      "Fold 7: Accuracy = 91.00%, Time = 2081.29 seconds\n",
      "Processing fold 8...\n",
      "Predicting using k-NN for fold 8...\n",
      "Fold 8: Accuracy = 92.40%, Time = 2357.44 seconds\n",
      "Processing fold 9...\n",
      "Predicting using k-NN for fold 9...\n",
      "Fold 9: Accuracy = 90.90%, Time = 2631.72 seconds\n",
      "Processing fold 10...\n",
      "Predicting using k-NN for fold 10...\n",
      "Fold 10: Accuracy = 91.00%, Time = 2896.84 seconds\n",
      "\n",
      "Cross-validation completed in 16642.71 seconds.\n",
      "Accuracy for each fold: ['89.90%', '93.10%', '91.30%', '90.70%', '90.60%', '91.40%', '91.00%', '92.40%', '90.90%', '91.00%']\n",
      "Mean accuracy: 91.23%\n",
      "Standard deviation of accuracy: 0.87%\n",
      "Best accuracy: 93.10%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Fetch and preprocess the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "X = X / 255.0  # Normalize the pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Euclidean Distance function\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Step 4: Implement k-NN without BallTree\n",
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    \"\"\"Predict labels using k-NN and Euclidean distance.\"\"\"\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each test point, calculate distances to all training points\n",
    "    for test_point in X_test:\n",
    "        distances = [euclidean_distance(test_point, train_point) for train_point in X_train]\n",
    "        \n",
    "        # Get indices of the k smallest distances\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = y_train[k_indices]\n",
    "        \n",
    "        # Majority vote\n",
    "        predicted_label = np.bincount(k_nearest_labels).argmax()\n",
    "        y_pred.append(predicted_label)\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Step 5: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "# Start cross-validation process\n",
    "start_time = time.time()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Indicate which fold is being processed\n",
    "    \n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Step 6: Predict using k-NN without BallTree\n",
    "    print(f\"Predicting using k-NN for fold {fold_idx}...\")\n",
    "    y_pred = knn_predict(X_train, y_train, X_test, k=3)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(accuracy)\n",
    "\n",
    "    # Track the time taken for this fold\n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {accuracy * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "\n",
    "# Step 7: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b221c6-abab-4576-9ba2-e662eaceda58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Processing fold 1...\n",
      "Fold 1: Accuracy = 90.40%, Time = 62.33 seconds\n",
      "Processing fold 2...\n",
      "Fold 2: Accuracy = 93.00%, Time = 127.82 seconds\n",
      "Processing fold 3...\n",
      "Fold 3: Accuracy = 90.90%, Time = 190.03 seconds\n",
      "Processing fold 4...\n",
      "Fold 4: Accuracy = 90.40%, Time = 249.82 seconds\n",
      "Processing fold 5...\n",
      "Fold 5: Accuracy = 90.50%, Time = 312.83 seconds\n",
      "Processing fold 6...\n",
      "Fold 6: Accuracy = 91.80%, Time = 380.30 seconds\n",
      "Processing fold 7...\n",
      "Fold 7: Accuracy = 91.40%, Time = 444.88 seconds\n",
      "Processing fold 8...\n",
      "Fold 8: Accuracy = 92.10%, Time = 509.06 seconds\n",
      "Processing fold 9...\n",
      "Fold 9: Accuracy = 91.30%, Time = 570.48 seconds\n",
      "Processing fold 10...\n",
      "Fold 10: Accuracy = 91.60%, Time = 631.69 seconds\n",
      "\n",
      "Cross-validation completed in 3479.25 seconds.\n",
      "Accuracy for each fold: ['90.40%', '93.00%', '90.90%', '90.40%', '90.50%', '91.80%', '91.40%', '92.10%', '91.30%', '91.60%']\n",
      "Mean accuracy: 91.34%\n",
      "Standard deviation of accuracy: 0.79%\n",
      "Best accuracy: 93.00%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Fetch and preprocess the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "X = X / 255.0  # Normalize the pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Define the custom cosine distance function\n",
    "def cosine_similarity(point1, point2):\n",
    "    \"\"\"Calculate the cosine similarity between two points.\"\"\"\n",
    "    dot_product = np.dot(point1, point2)\n",
    "    norm1 = np.linalg.norm(point1)\n",
    "    norm2 = np.linalg.norm(point2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "def cosine_distance(x, y):\n",
    "    \"\"\"Calculate the cosine distance between two vectors.\"\"\"\n",
    "    return 1 - cosine_similarity(x, y)\n",
    "\n",
    "# Step 4: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Function to perform k-NN without BallTree\n",
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        # Calculate distances to all training points\n",
    "        distances = [cosine_distance(test_point, train_point) for train_point in X_train]\n",
    "        \n",
    "        # Get indices of the k smallest distances\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = y_train[k_indices]\n",
    "        \n",
    "        # Majority vote\n",
    "        predicted_label = np.bincount(k_nearest_labels).argmax()\n",
    "        y_pred.append(predicted_label)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Indicate which fold is being processed\n",
    "    \n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Test k-NN without Ball Tree\n",
    "    y_pred = knn_predict(X_train, y_train, X_test, k=3)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(accuracy)\n",
    "\n",
    "    # Track the time taken for this fold\n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {accuracy * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "\n",
    "# Step 5: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6715f2c-9276-4bb4-a53f-b8aed8efd2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Processing fold 1...\n",
      "Predicting using k-NN for fold 1...\n",
      "Fold 1: Accuracy = 91.50%, Time = 225.07 seconds\n",
      "Processing fold 2...\n",
      "Predicting using k-NN for fold 2...\n",
      "Fold 2: Accuracy = 94.70%, Time = 449.87 seconds\n",
      "Processing fold 3...\n",
      "Predicting using k-NN for fold 3...\n",
      "Fold 3: Accuracy = 93.40%, Time = 674.65 seconds\n",
      "Processing fold 4...\n",
      "Predicting using k-NN for fold 4...\n",
      "Fold 4: Accuracy = 91.90%, Time = 898.45 seconds\n",
      "Processing fold 5...\n",
      "Predicting using k-NN for fold 5...\n",
      "Fold 5: Accuracy = 92.70%, Time = 1110.96 seconds\n",
      "Processing fold 6...\n",
      "Predicting using k-NN for fold 6...\n",
      "Fold 6: Accuracy = 93.30%, Time = 1289.30 seconds\n",
      "Processing fold 7...\n",
      "Predicting using k-NN for fold 7...\n",
      "Fold 7: Accuracy = 92.00%, Time = 1467.10 seconds\n",
      "Processing fold 8...\n",
      "Predicting using k-NN for fold 8...\n",
      "Fold 8: Accuracy = 93.80%, Time = 1532.64 seconds\n",
      "Processing fold 9...\n",
      "Predicting using k-NN for fold 9...\n",
      "Fold 9: Accuracy = 93.70%, Time = 1591.00 seconds\n",
      "Processing fold 10...\n",
      "Predicting using k-NN for fold 10...\n",
      "Fold 10: Accuracy = 92.80%, Time = 1649.05 seconds\n",
      "\n",
      "Cross-validation completed in 10888.08 seconds.\n",
      "Accuracy for each fold: ['91.50%', '94.70%', '93.40%', '91.90%', '92.70%', '93.30%', '92.00%', '93.80%', '93.70%', '92.80%']\n",
      "Mean accuracy: 92.98%\n",
      "Standard deviation of accuracy: 0.94%\n",
      "Best accuracy: 94.70%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Fetch and preprocess the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "X = X / 255.0  # Normalize pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Manhattan Distance function\n",
    "def manhattan_distance(x, y):\n",
    "    \"\"\"Calculate the Manhattan (L1) distance between two points.\"\"\"\n",
    "    return np.sum(np.abs(x - y))\n",
    "\n",
    "# Step 4: Implement k-NN without BallTree\n",
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    \"\"\"Predict labels using k-NN and Manhattan distance.\"\"\"\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each test point, calculate distances to all training points\n",
    "    for test_point in X_test:\n",
    "        distances = [manhattan_distance(test_point, train_point) for train_point in X_train]\n",
    "        \n",
    "        # Get indices of the k smallest distances\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = y_train[k_indices]\n",
    "        \n",
    "        # Majority vote\n",
    "        predicted_label = np.bincount(k_nearest_labels).argmax()\n",
    "        y_pred.append(predicted_label)\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Step 5: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "# Start cross-validation process\n",
    "start_time = time.time()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Indicate which fold is being processed\n",
    "    \n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Step 6: Predict using k-NN without BallTree\n",
    "    print(f\"Predicting using k-NN for fold {fold_idx}...\")\n",
    "    y_pred = knn_predict(X_train, y_train, X_test, k=3)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(accuracy)\n",
    "\n",
    "    # Track the time taken for this fold\n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {accuracy * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "\n",
    "# Step 7: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01ff60-b386-4e14-98a8-edc1d7689788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
