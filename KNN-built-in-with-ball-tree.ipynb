{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48de55af-0c56-4cd1-ba1f-92e6cc9ead49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Processing fold 1...\n",
      "Fold 1: Accuracy = 89.90%, Time = 13.15 seconds\n",
      "Processing fold 2...\n",
      "Fold 2: Accuracy = 93.10%, Time = 42.59 seconds\n",
      "Processing fold 3...\n",
      "Fold 3: Accuracy = 91.30%, Time = 92.96 seconds\n",
      "Processing fold 4...\n",
      "Fold 4: Accuracy = 90.70%, Time = 158.35 seconds\n",
      "Processing fold 5...\n",
      "Fold 5: Accuracy = 90.60%, Time = 213.16 seconds\n",
      "Processing fold 6...\n",
      "Fold 6: Accuracy = 91.40%, Time = 255.98 seconds\n",
      "Processing fold 7...\n",
      "Fold 7: Accuracy = 91.00%, Time = 296.20 seconds\n",
      "Processing fold 8...\n",
      "Fold 8: Accuracy = 92.40%, Time = 336.92 seconds\n",
      "Processing fold 9...\n",
      "Fold 9: Accuracy = 90.90%, Time = 376.35 seconds\n",
      "Processing fold 10...\n",
      "Fold 10: Accuracy = 91.00%, Time = 415.00 seconds\n",
      "\n",
      "Cross-validation completed in 2200.65 seconds.\n",
      "Accuracy for each fold: ['89.90%', '93.10%', '91.30%', '90.70%', '90.60%', '91.40%', '91.00%', '92.40%', '90.90%', '91.00%']\n",
      "Mean accuracy: 91.23%\n",
      "Standard deviation of accuracy: 0.87%\n",
      "Best accuracy: 93.10%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "                    \n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "                   \n",
    "X = X / 255.0  # Normalize the pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "# Initialize the K-NN classifier with Ball Tree and Euclidean distance\n",
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric='euclidean')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Print which fold is being processed\n",
    "\n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Train the model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {score * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "    \n",
    "# Step 4: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c74543aa-560f-42f0-878a-cd48e6135449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Processing fold 1...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['ball_tree']) to get valid options. Metric can also be a callable function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y[train_idx], y[test_idx]\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     46\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# KNeighborsClassifier.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    219\u001b[0m )\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:519\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m    517\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_ \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:453\u001b[0m, in \u001b[0;36mNeighborsBase._check_algorithm_metric\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree does not support callable metric \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction call overhead will result\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min very poor performance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[0;32m    449\u001b[0m         )\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m VALID_METRICS[alg_check] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric, DistanceMetric\n\u001b[0;32m    452\u001b[0m ):\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not valid. Use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorted(sklearn.neighbors.VALID_METRICS[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get valid options. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric can also be a callable function.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric, alg_check)\n\u001b[0;32m    458\u001b[0m     )\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['ball_tree']) to get valid options. Metric can also be a callable function."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "\n",
    "X = X / 255.0  # Normalize the pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "# Initialize the K-NN classifier with Ball Tree and Cosine distance\n",
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric='cosine')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Print which fold is being processed\n",
    "\n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Train the model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {score * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "    \n",
    "# Step 4: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b38fad-48e6-4b6b-9c3b-4bb2c7d8d33a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "\n",
    "X = X / 255.0  # Normalize the pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "# Initialize the K-NN classifier with Ball Tree and Manhattan distance\n",
    "knn = KNeighborsClassifier(n_neighbors=3, algorithm='ball_tree', metric='manhattan')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Print which fold is being processed\n",
    "\n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Train the model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {score * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "    \n",
    "# Step 4: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d0b78-cbe1-43a4-86da-5637880d92fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
