{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fff188d-eff4-4224-b2cc-85e91c2e9779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Applying PCA...\n",
      "Reduced data shape: (10000, 283)\n",
      "Processing fold 1...\n",
      "Predicting using k-NN for fold 1...\n",
      "Fold 1: Accuracy = 90.80%, Time = 374.16 seconds\n",
      "Processing fold 2...\n",
      "Predicting using k-NN for fold 2...\n",
      "Fold 2: Accuracy = 93.90%, Time = 630.32 seconds\n",
      "Processing fold 3...\n",
      "Predicting using k-NN for fold 3...\n",
      "Fold 3: Accuracy = 91.80%, Time = 871.80 seconds\n",
      "Processing fold 4...\n",
      "Predicting using k-NN for fold 4...\n",
      "Fold 4: Accuracy = 91.20%, Time = 1114.85 seconds\n",
      "Processing fold 5...\n",
      "Predicting using k-NN for fold 5...\n",
      "Fold 5: Accuracy = 90.40%, Time = 1360.21 seconds\n",
      "Processing fold 6...\n",
      "Predicting using k-NN for fold 6...\n",
      "Fold 6: Accuracy = 92.40%, Time = 1600.69 seconds\n",
      "Processing fold 7...\n",
      "Predicting using k-NN for fold 7...\n",
      "Fold 7: Accuracy = 91.30%, Time = 1845.26 seconds\n",
      "Processing fold 8...\n",
      "Predicting using k-NN for fold 8...\n",
      "Fold 8: Accuracy = 92.00%, Time = 2088.27 seconds\n",
      "Processing fold 9...\n",
      "Predicting using k-NN for fold 9...\n",
      "Fold 9: Accuracy = 92.00%, Time = 2331.17 seconds\n",
      "Processing fold 10...\n",
      "Predicting using k-NN for fold 10...\n",
      "Fold 10: Accuracy = 91.30%, Time = 2572.50 seconds\n",
      "\n",
      "Cross-validation completed in 14789.23 seconds.\n",
      "Accuracy for each fold: ['90.80%', '93.90%', '91.80%', '91.20%', '90.40%', '92.40%', '91.30%', '92.00%', '92.00%', '91.30%']\n",
      "Mean accuracy: 91.71%\n",
      "Standard deviation of accuracy: 0.93%\n",
      "Best accuracy: 93.90%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Fetch and preprocess the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "X = X / 255.0  # Normalize the pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Apply PCA for dimensionality reduction\n",
    "print(\"Applying PCA...\")\n",
    "pca = PCA(n_components=0.95)  # Retain enough components to explain 95% variance\n",
    "X = pca.fit_transform(X)\n",
    "print(f\"Reduced data shape: {X.shape}\")\n",
    "\n",
    "# Step 4: Euclidean Distance function\n",
    "def euclidean_distance(x, y):\n",
    "    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Step 5: Implement k-NN without BallTree\n",
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    \"\"\"Predict labels using k-NN and Euclidean distance.\"\"\"\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each test point, calculate distances to all training points\n",
    "    for test_point in X_test:\n",
    "        distances = [euclidean_distance(test_point, train_point) for train_point in X_train]\n",
    "        \n",
    "        # Get indices of the k smallest distances\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = y_train[k_indices]\n",
    "        \n",
    "        # Majority vote\n",
    "        predicted_label = np.bincount(k_nearest_labels).argmax()\n",
    "        y_pred.append(predicted_label)\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Step 6: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "# Start cross-validation process\n",
    "start_time = time.time()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Indicate which fold is being processed\n",
    "    \n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Step 7: Predict using k-NN without BallTree\n",
    "    print(f\"Predicting using k-NN for fold {fold_idx}...\")\n",
    "    y_pred = knn_predict(X_train, y_train, X_test, k=3)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(accuracy)\n",
    "\n",
    "    # Track the time taken for this fold\n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {accuracy * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "\n",
    "# Step 8: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b221c6-abab-4576-9ba2-e662eaceda58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Applying PCA...\n",
      "Reduced data shape: (10000, 283)\n",
      "Processing fold 1...\n",
      "Fold 1: Accuracy = 90.90%, Time = 55.32 seconds\n",
      "Processing fold 2...\n",
      "Fold 2: Accuracy = 93.40%, Time = 117.19 seconds\n",
      "Processing fold 3...\n",
      "Fold 3: Accuracy = 92.40%, Time = 177.31 seconds\n",
      "Processing fold 4...\n",
      "Fold 4: Accuracy = 90.30%, Time = 238.18 seconds\n",
      "Processing fold 5...\n",
      "Fold 5: Accuracy = 91.70%, Time = 297.16 seconds\n",
      "Processing fold 6...\n",
      "Fold 6: Accuracy = 93.00%, Time = 360.45 seconds\n",
      "Processing fold 7...\n",
      "Fold 7: Accuracy = 92.70%, Time = 421.39 seconds\n",
      "Processing fold 8...\n",
      "Fold 8: Accuracy = 93.50%, Time = 486.86 seconds\n",
      "Processing fold 9...\n",
      "Fold 9: Accuracy = 92.50%, Time = 548.27 seconds\n",
      "Processing fold 10...\n",
      "Fold 10: Accuracy = 92.70%, Time = 609.83 seconds\n",
      "\n",
      "Cross-validation completed in 3311.96 seconds.\n",
      "Accuracy for each fold: ['90.90%', '93.40%', '92.40%', '90.30%', '91.70%', '93.00%', '92.70%', '93.50%', '92.50%', '92.70%']\n",
      "Mean accuracy: 92.31%\n",
      "Standard deviation of accuracy: 0.99%\n",
      "Best accuracy: 93.50%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Fetch and preprocess the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "X = X / 255.0  # Normalize the pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Apply PCA for dimensionality reduction\n",
    "print(\"Applying PCA...\")\n",
    "pca = PCA(n_components=0.95)  # Retain enough components to explain 95% variance\n",
    "X = pca.fit_transform(X)\n",
    "print(f\"Reduced data shape: {X.shape}\")\n",
    "\n",
    "# Step 4: Define the custom cosine distance function\n",
    "def cosine_similarity(point1, point2):\n",
    "    \"\"\"Calculate the cosine similarity between two points.\"\"\"\n",
    "    dot_product = np.dot(point1, point2)\n",
    "    norm1 = np.linalg.norm(point1)\n",
    "    norm2 = np.linalg.norm(point2)\n",
    "    return dot_product / (norm1 * norm2)\n",
    "\n",
    "def cosine_distance(x, y):\n",
    "    \"\"\"Calculate the cosine distance between two vectors.\"\"\"\n",
    "    return 1 - cosine_similarity(x, y)\n",
    "\n",
    "# Step 5: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Function to perform 1-NN without BallTree\n",
    "def knn_predict(X_train, y_train, X_test):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        # Calculate distances to all training points\n",
    "        distances = [cosine_distance(test_point, train_point) for train_point in X_train]\n",
    "        \n",
    "        # Get index of the smallest distance (nearest neighbor)\n",
    "        nearest_index = np.argmin(distances)\n",
    "        predicted_label = y_train[nearest_index]\n",
    "        \n",
    "        y_pred.append(predicted_label)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Indicate which fold is being processed\n",
    "    \n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Test 1-NN without Ball Tree\n",
    "    y_pred = knn_predict(X_train, y_train, X_test)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(accuracy)\n",
    "\n",
    "    # Track the time taken for this fold\n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {accuracy * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "\n",
    "# Step 6: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6715f2c-9276-4bb4-a53f-b8aed8efd2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching MNIST dataset...\n",
      "Using first 10,000 images: 10000 training samples.\n",
      "Standardizing features...\n",
      "Applying PCA...\n",
      "Reduced data shape: (10000, 283)\n",
      "Processing fold 1...\n",
      "Predicting using k-NN for fold 1...\n",
      "Fold 1: Accuracy = 87.20%, Time = 191.39 seconds\n",
      "Processing fold 2...\n",
      "Predicting using k-NN for fold 2...\n",
      "Fold 2: Accuracy = 91.30%, Time = 384.87 seconds\n",
      "Processing fold 3...\n",
      "Predicting using k-NN for fold 3...\n",
      "Fold 3: Accuracy = 89.70%, Time = 577.12 seconds\n",
      "Processing fold 4...\n",
      "Predicting using k-NN for fold 4...\n",
      "Fold 4: Accuracy = 87.90%, Time = 766.06 seconds\n",
      "Processing fold 5...\n",
      "Predicting using k-NN for fold 5...\n",
      "Fold 5: Accuracy = 89.00%, Time = 958.87 seconds\n",
      "Processing fold 6...\n",
      "Predicting using k-NN for fold 6...\n",
      "Fold 6: Accuracy = 90.80%, Time = 1149.18 seconds\n",
      "Processing fold 7...\n",
      "Predicting using k-NN for fold 7...\n",
      "Fold 7: Accuracy = 88.40%, Time = 1339.68 seconds\n",
      "Processing fold 8...\n",
      "Predicting using k-NN for fold 8...\n",
      "Fold 8: Accuracy = 91.20%, Time = 1530.18 seconds\n",
      "Processing fold 9...\n",
      "Predicting using k-NN for fold 9...\n",
      "Fold 9: Accuracy = 90.00%, Time = 1720.51 seconds\n",
      "Processing fold 10...\n",
      "Predicting using k-NN for fold 10...\n",
      "Fold 10: Accuracy = 90.00%, Time = 1910.16 seconds\n",
      "\n",
      "Cross-validation completed in 10528.02 seconds.\n",
      "Accuracy for each fold: ['87.20%', '91.30%', '89.70%', '87.90%', '89.00%', '90.80%', '88.40%', '91.20%', '90.00%', '90.00%']\n",
      "Mean accuracy: 89.55%\n",
      "Standard deviation of accuracy: 1.33%\n",
      "Best accuracy: 91.30%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Fetch and preprocess the MNIST dataset\n",
    "print(\"Fetching MNIST dataset...\")\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "X, y = X[:10000], y[:10000]  # Select first 10,000 images for processing\n",
    "print(f\"Using first 10,000 images: {X.shape[0]} training samples.\")\n",
    "\n",
    "X = X / 255.0  # Normalize pixel values to [0, 1]\n",
    "y = y.astype(int)  # Convert labels to integers\n",
    "\n",
    "# Step 2: Standardize the features\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Apply PCA for dimensionality reduction\n",
    "print(\"Applying PCA...\")\n",
    "pca = PCA(n_components=0.95)  # Retain enough components to explain 95% variance\n",
    "X = pca.fit_transform(X)\n",
    "print(f\"Reduced data shape: {X.shape}\")\n",
    "\n",
    "# Step 4: Manhattan Distance function\n",
    "def manhattan_distance(x, y):\n",
    "    \"\"\"Calculate the Manhattan (L1) distance between two points.\"\"\"\n",
    "    return np.sum(np.abs(x - y))\n",
    "\n",
    "# Step 5: Implement k-NN without BallTree\n",
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    \"\"\"Predict labels using k-NN and Manhattan distance.\"\"\"\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each test point, calculate distances to all training points\n",
    "    for test_point in X_test:\n",
    "        distances = [manhattan_distance(test_point, train_point) for train_point in X_train]\n",
    "        \n",
    "        # Get indices of the k smallest distances\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = y_train[k_indices]\n",
    "        \n",
    "        # Majority vote\n",
    "        predicted_label = np.bincount(k_nearest_labels).argmax()\n",
    "        y_pred.append(predicted_label)\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Step 6: Use 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "fold_times = []\n",
    "\n",
    "# Start cross-validation process\n",
    "start_time = time.time()\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    print(f\"Processing fold {fold_idx}...\")  # Indicate which fold is being processed\n",
    "    \n",
    "    # Split the data for the current fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Step 7: Predict using k-NN without BallTree\n",
    "    print(f\"Predicting using k-NN for fold {fold_idx}...\")\n",
    "    y_pred = knn_predict(X_train, y_train, X_test, k=3)\n",
    "\n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    fold_scores.append(accuracy)\n",
    "\n",
    "    # Track the time taken for this fold\n",
    "    fold_end_time = time.time()\n",
    "    fold_time = fold_end_time - start_time\n",
    "    fold_times.append(fold_time)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Accuracy = {accuracy * 100:.2f}%, Time = {fold_time:.2f} seconds\")\n",
    "\n",
    "# Step 8: Report overall results\n",
    "mean_accuracy = np.mean(fold_scores)\n",
    "std_accuracy = np.std(fold_scores)\n",
    "total_time = np.sum(fold_times)\n",
    "best_accuracy = np.max(fold_scores)\n",
    "\n",
    "print(f\"\\nCross-validation completed in {total_time:.2f} seconds.\")\n",
    "print(f\"Accuracy for each fold: {[f'{score * 100:.2f}%' for score in fold_scores]}\")\n",
    "print(f\"Mean accuracy: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Standard deviation of accuracy: {std_accuracy * 100:.2f}%\")\n",
    "print(f\"Best accuracy: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01ff60-b386-4e14-98a8-edc1d7689788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
